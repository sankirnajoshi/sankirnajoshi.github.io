{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Copy of RNN-task.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sankirnajoshi/intro-to-dl/blob/master/week5/RNN-task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y-74nwkD0pk",
        "colab_type": "text"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiFnyH5rD3Wj",
        "colab_type": "code",
        "outputId": "719d9199-1182-4aaf-923a-7b7fe8ae2c9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()\n",
        "# setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week2_honor()\n",
        "# setup_google_colab.setup_week3()\n",
        "# setup_google_colab.setup_week4()\n",
        "setup_google_colab.setup_week5()\n",
        "# setup_google_colab.setup_week6()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-04 18:49:41--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3636 (3.6K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "\rsetup_google_colab.   0%[                    ]       0  --.-KB/s               \rsetup_google_colab. 100%[===================>]   3.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-01-04 18:49:41 (93.0 MB/s) - ‘setup_google_colab.py’ saved [3636/3636]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "o1TaqrDGD0p6",
        "colab_type": "code",
        "outputId": "984e9954-34ef-4db2-a086-e00696dd5e6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PYeDCdOD0qs",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyaOE17uHpjX",
        "colab_type": "code",
        "outputId": "966472a7-b748-4dc1-c454-fe17858d7727",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "! pip install wget"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9681 sha256=1be0cf40ba1ae90460cf29727375ddb98ddf009dca250b0e0ce7e15b6fea5044\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCeMaP00E8Qx",
        "colab_type": "code",
        "outputId": "35f6d141-24f8-40b4-897b-7874e81b1cf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "## Upload the names file from the link : https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/week5/names after mounting the google drive."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "SsopEi-OD0q4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "cU0XSefeD0rW",
        "colab_type": "code",
        "outputId": "de652dec-ff0b-494b-cc22-a1969b584772",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "_aoOyUlvD0ru",
        "colab_type": "code",
        "outputId": "34c1ad11-3c38-4766-cd1f-04d3f396c445",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ9/MLCMOfTOzjPx/p/4cUF1Gcl0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZhXjWV1D0sO",
        "colab_type": "text"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "U0mPg00oD0sa",
        "colab_type": "code",
        "outputId": "70ead855-4571-4c8e-85ee-495d3735d07c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tokens = set(''.join(names[:])) ### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "tokens = list(tokens)\n",
        "tokens.append('#')\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARnTHuX3D0sz",
        "colab_type": "text"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "9Ga1WyTAD0s7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_to_id = {}### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "\n",
        "for i in range(n_tokens):\n",
        "    token_to_id[tokens[i]] = i\n",
        "    \n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "kzPUFQzyD0tT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "h0jQEhSrD0tx",
        "colab_type": "code",
        "outputId": "a13b1151-1df7-445d-971c-3fce44212384",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[ 9 15 46 29 41 29 17  2 55]\n",
            " [ 9 31  2 48  0  4 55 55 55]\n",
            " [ 9 53  0 13  1  1 13 17 55]\n",
            " [ 9 31 13 48 24 29 36 36 17]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9gJ1frSD0uG",
        "colab_type": "text"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/sankirnajoshi/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "iyAHdQMBD0uQ",
        "colab_type": "code",
        "outputId": "e7c83f0e-36ff-4e2c-bb79-fd4eb1badd64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/keras_utils.py:68: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:79: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:82: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:84: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:77: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "jQTODm2_D0up",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation='tanh')  ### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation='softmax')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMFmtxaZD0u6",
        "colab_type": "text"
      },
      "source": [
        "[link text](https://)We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/sankirnajoshi/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "M_GwsDEaD0vC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = tf.concat([x_t_emb, h_t], 1)### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h)### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next) ### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6twisFkQD0vY",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "n4tS9N0CD0ve",
        "colab_type": "code",
        "outputId": "d7c3100f-6f2e-4dcf-ccd2-239c0c2c7376",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3535: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWhWuBqMD0vx",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "rXAt_BerD0v2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwZ1wswnD0wM",
        "colab_type": "text"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "kZ9PRYLrD0wS",
        "colab_type": "code",
        "outputId": "56a308b1-ed46-49bc-9f32-60e6fea25c61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "from keras.objectives import categorical_crossentropy\n",
        "loss = tf.reduce_mean(categorical_crossentropy(answers_matrix, predictions_matrix)) ### YOUR CODE HERE\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2745: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2749: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZALxos3DD0wk",
        "colab_type": "text"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "InBXN0vdD0wp",
        "colab_type": "code",
        "outputId": "f74c5c38-49c8-4ee1-9ac5-3d4318260ba1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlFI2oQFdKaVs4v8BVPjt+DVf0RUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3nmzz60D0w3",
        "colab_type": "text"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "RYTq-nSRD0w_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "ORV2bL6UD0xP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "O34U3ae1D0xb",
        "colab_type": "code",
        "outputId": "9d053f85-b1b6-4018-ad97-43e4f907c7fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Fars\n",
            " Annele\n",
            " Voenba\n",
            " Vyawda\n",
            " Leda\n",
            " ULenty\n",
            " Livik\n",
            " Mafgtal\n",
            " Baril\n",
            " Doislal\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "hLbQ0KlqD0xw",
        "colab_type": "code",
        "outputId": "e8c0dc30-8b8b-4767-b0a8-3e1479910971",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trump\n",
            " Trump\n",
            " TrumpB\n",
            " Trumpa\n",
            " Trumpa\n",
            " Trumpio\n",
            " Trumpea\n",
            " Trumpe\n",
            " Trumpar\n",
            " Trumpa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbixb1xoD0x9",
        "colab_type": "text"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "UnVvBCzQD0yA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"PngruUBm4gGlq5fD\"\n",
        "COURSERA_EMAIL = \"sankirna1292@gmail.com\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "TovDj292D0yW",
        "colab_type": "code",
        "outputId": "2b8ac0a4-8240-4246-a022-5a576365f650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "You used an invalid email or your token may have expired. Please make sure you have entered all fields correctly. Try generating a new token if the issue still persists.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BL1AV4OD0yl",
        "colab_type": "text"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "qrhqTr1ND0yr",
        "colab_type": "text"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "hw5y79bdD0yv",
        "colab_type": "code",
        "outputId": "7ae5c343-02c5-49a6-9e80-4eeae195dc7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-26-5f3812e903bf>:13: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-26-5f3812e903bf>:17: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-5f3812e903bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0minput_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mpredicted_probas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM outputs for each step [batch,time,n_tokens]:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2751\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2752\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 2753\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   2754\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2755\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   2243\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 2245\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   2246\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2168\u001b[0m         expand_composites=True)\n\u001b[1;32m   2169\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2170\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2171\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2172\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence_or_composite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   2703\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   2704\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 2705\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2706\u001b[0m       \u001b[0mtry_to_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    882\u001b[0m           skip_conditionals=True)\n\u001b[1;32m    883\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[0;31m# Keras cells always wrap state as list, even if it's a single tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_keras_rnn_cell\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# method.  See the class docstring for more details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     return base_layer.Layer.__call__(\n\u001b[0;32m--> 386\u001b[0;31m         self, inputs, state, scope=scope, *args, **kwargs)\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m       \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m       \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, inputs_shape)\u001b[0m\n\u001b[1;32m    449\u001b[0m       raise ValueError(\"Expected inputs.shape[-1] to be known, saw shape: %s\" %\n\u001b[1;32m    450\u001b[0m                        str(inputs_shape))\n\u001b[0;32m--> 451\u001b[0;31m     \u001b[0m_check_supported_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0minput_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m_check_supported_dtypes\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m   1345\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m     raise ValueError(\"RNN cell only supports floating point inputs, \"\n\u001b[0;32m-> 1347\u001b[0;31m                      \"but saw dtype: %s\" % dtype)\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: RNN cell only supports floating point inputs, but saw dtype: <dtype: 'int32'>"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlLKSy46D0zA",
        "colab_type": "text"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "qUIQ50vlD0zG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "lqsFoAA5D0zQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}